{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## $\\color{darkblue}{\\mathbf{\\text{ Table of Contents.}}}$\n",
    "\n",
    "\n",
    "[**$\\color{orange}{\\mathbf{IN.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Introduction.}}}}$**](#introduction) \n",
    "\n",
    "[**$\\color{orange}{\\mathbf{LA.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Linear Algebra.}}}}$**](#linalg)\n",
    "\n",
    "[**$\\color{orange}{\\mathbf{ST.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Statistics.}}}}$**](#stats)\n",
    "\n",
    "[**$\\color{orange}{\\mathbf{PT.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Probability Theory.}}}}$**](#prob)\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; [**$\\color{orange}{\\mathbf{PT.1.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Random Variables.}}}}$**](#prob_rv)\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; [**$\\color{orange}{\\mathbf{PT.2.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Properties of Probability.}}}}$**](#prob_prop)\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; [**$\\color{orange}{\\mathbf{PT.3.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Parametric Distributions.}}}}$**](#prob_dist)\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; [**$\\color{orange}{\\mathbf{PT.3.1.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Distributions: Multinomial Distribution.}}}}$**](#prob_dist_multi)\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; [**$\\color{orange}{\\mathbf{PT.3.2.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ MultiVariate Guassian Distribution.}}}}$**](#prob_dist_mvn)\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; [**$\\color{orange}{\\mathbf{PT.4.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Bayes Theorem.}}}}$**](#prob_bayes)\n",
    "\n",
    "[**$\\color{orange}{\\mathbf{NT.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Numerical Techniques.}}}}$**](#num_tech)\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; [**$\\color{orange}{\\mathbf{NT.1.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ Maximizing a function via Matrix Calculus}}}}$**](#num_max_cal)\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; [**$\\color{orange}{\\mathbf{NT.2.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ MLE Techniques.}}}}$**](#num_mle)\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; [**$\\color{orange}{\\mathbf{NT.3.}} \\color{darkblue}{\\mathbf{\\underline{\\text{ EM Techniques.}}}}$**](#num_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# $\\color{orange}{\\mathbf{IN.}} \\color{darkblue}{\\mathbf{\\text{ Introduction}}} $<a name=\"introduction\"></a>\n",
    "\n",
    "\n",
    "We will cover in short the details needed for various derivations and mathemathical formulations.\n",
    "\n",
    "Since many code pattern will have these common components, it makes sense to seperate it out.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let define some of the terms, before we move forward\n",
    "\n",
    "##### Convention used\n",
    "\n",
    "\n",
    "| Symbol                         | description                                                   |\n",
    "|:-------------------------------|:--------------------------------------------------------------|\n",
    "| $\\color{darkred}{x_{4}}$       | scaler is represented as lowercase with dimension subscript   |\n",
    "| $\\color{darkred}{\\mathbf{x}}$  | vector is represented as a bold lowercase                     |\n",
    "| $\\color{darkred}{\\mathbf{X}}$  | matrix is represented as bold uppercase                       |\n",
    "| $\\color{darkred}{rv}$          | random variable is represented by lowercase with no subscript |\n",
    "| $\\color{darkred}{\\mathbf{rv}}$ | vector of random variable is represented by uppercase         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{orange}{\\mathbf{LA.}} \\color{darkblue}{\\mathbf{\\text{ Linear Algebra}}} $<a name=\"linalg\"></a>\n",
    "\n",
    "\n",
    "To represent many data points and compactly manupulate it's operations linear algebra is an excellent tool. We recommend this excellent [book by Gibert Strang](https://www.amazon.com/Introduction-Linear-Algebra-Fourth-Gilbert/dp/0980232716) and/or [wiki](https://en.wikipedia.org/wiki/Linear_algebra). We will cover a small portion relevant to current topic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\color{orange}{\\mathbf{LA.1.}} \\color{darkblue}{\\mathbf{\\text{ Scalar variable.}}} $\n",
    "\n",
    "When we collect data each of the measurement is scalar. We could collect N samples of each scalar. It is usually represented by non bold word with the subscript representing the index i.e \n",
    "$ \\color{darkred}{x_{i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### $\\color{orange}{\\mathbf{LA.2.}} \\color{darkblue}{\\mathbf{\\text{ Vector variable.}}}$\n",
    "\n",
    "During data collection, we might measure various attributes, for example age, gender etc of the test subject.\n",
    "to compactly represent M scalars for each subject, vector is used, it is just a tuple of M scalars and uniquely describes a point in M dimensional space.\n",
    "\n",
    "(**Note**: We use Transpose operation to compactly represent column vector as row)\n",
    "\n",
    "(**Note**: A vector is a point in M dimensional space)\n",
    "\n",
    "\n",
    "###### Represenation of a sample using vector\n",
    "Let the original input dataset be represented by M number of dimensions i.e each sample consist of M different 1D data point and together they form a sample data point column vector represented by bold word i.e $\\mathbf{x}  = (x_{1}, x_{2} \\cdots x_{d})^{T}$. \n",
    "\n",
    "\n",
    "Since we will be having N different data point, we would like to suffix $ i $ for the ith sample and the ith data point vector is \n",
    "$$ \n",
    "\\color{darkred}{\n",
    "\\mathbf{x_{i}}  = (x_{i1}, x_{i2} \\cdots , x_{id})^{T}\n",
    "}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\color{orange}{\\mathbf{LA.3.}} \\color{darkblue}{\\mathbf{\\text{ Matrix variable.}}} $\n",
    "\n",
    "\n",
    "##### Representation of Whole dataset.\n",
    "As we noted in previous sub section that each subject or sample can be represented by one column vector. If we take N such measurement, we can compactly represent all those N measurements across M dimension $N \\times M$ matrix.\n",
    "\n",
    "$$ \n",
    "\\color{darkred}{\n",
    "\\mathbf{X} = ( \\mathbf{x_{1}}^{T}, \\mathbf{x_{2}}^{T}, \\cdots  \\mathbf{x_{i}}^{T} \\cdots ,\\mathbf{x_{n}}^{T} )^{T}\n",
    "}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{orange}{\\mathbf{ST.}} \\color{darkblue}{\\mathbf{\\text{ Statistics.}}} $<a name=\"stats\"></a>\n",
    "\n",
    "\n",
    "Statistics find applications in variety of fields including Machine Learning. It is a short representation of a lot of information. We recommend this excellent [book by David Freeman](https://www.amazon.com/Statistics-4th-David-Freedman/dp/0393929728/ref=sr_1_1?s=books&ie=UTF8&qid=1539282517&sr=1-1&keywords=statistics+david+freedman+4th+edition) and/or [wiki](https://en.wikipedia.org/wiki/Statistics). We will cover a small portion relevant to current topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### $\\color{orange}{\\mathbf{ST.0.}} \\color{darkblue}{\\mathbf{\\text{Mean of one dimensional i.e scalar variable.}}} $\n",
    "\n",
    "\n",
    "  If we takes N samples of a scalar variable $v$ and we can approximate it by it's average i.e. mean as follows:\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "mean(v) = \\mu = \\overline{v} = \\frac{1}{N}\\sum_{i=1}^{N}v\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### $\\color{orange}{\\mathbf{ST.1.}} \\color{darkblue}{\\mathbf{\\text{Variance of one dimensional i.e scalar variable.}}} $\n",
    "\n",
    "\n",
    "  If we takes N samples of a random variable $v$ with zero mean, then it's variance is given by \n",
    "$$\n",
    "\\color{darkred}{\n",
    "variance(v) = \\sigma^2 = \\frac{1}{N}\\sum_{i=1}^{N}v^2\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\color{orange}{\\mathbf{ST.2.}} \\color{darkblue}{\\mathbf{\\text{ Standardization of data points.}}} $\n",
    "\n",
    "If we shift each of the dimensions by it's mean then we would have standardized data. The advantage of this would be simpler math.\n",
    "\n",
    "We would also like to divide it by dispersion i.e standard deviation because this will remove any bias associated with measuring units i.e measurement in inch vs cm etc.\n",
    "\n",
    "it means new i'th sample is represented as $\\mathbf{s_{i}}  = (s_{i1}, s_{i2} \\cdots , s_{id})^{T}$ i.e a column vector of standardized dimensions $s_{ij}$\n",
    "\n",
    "Each of the i'th samples' j'th dimension is represented as follows\n",
    "\n",
    "$$s_{ij} = \\frac{x_{ij} - \\overline{x_{j}}}{ \\sigma_{x_{j}}}$$\n",
    "\n",
    "\n",
    " \n",
    "Where\n",
    "  * Average for jth dimension $\\Rightarrow  \\overline{x_{j}} = \\frac{1}{N}\\Sigma x_{ij}$\n",
    "  \n",
    "  * Standard Variance for jth dimension  $\\Rightarrow  \\sigma_{x_{j}} = \\sqrt[2]{\\frac{1}{N}\\sum_{i=1}^{N}(x_{ij} - \\overline{x_{j}})^2}$\n",
    "  \n",
    "  \n",
    "and new standardized data matrix of size $N \\times M$ becomes \n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\mathbf{S} = ( \\mathbf{s_{1}}^{T}, \\mathbf{s_{2}}^{T}, \\cdots  \\mathbf{s_{i}}^{T} \\cdots ,\\mathbf{s_{n}}^{T} )^{T}\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\color{orange}{\\mathbf{ST.3.}} \\color{darkblue}{\\mathbf{\\text{ Covariance of M dimensional Vector.}}} $\n",
    "\n",
    "\n",
    "If we collect N samples for one dimensional data, then we know that using mean and variance we can get a good perspective on data. In short, using sufficient statistics i.e mean and variance allows us to have compression and remove the noise. The natural question is what to do when we have more than one dimensions to data i.e say M dimensions. Well how about characterizing it by M mean and M variances? This seems intuitively right, but here we are assuming that there is no co-relation or co-variance between any two dimensions. What if we want to account for this? The approach would be to compute variances between two dimensions and it is called covariance. Since we have assumed without loss of generality that each dimension has zero mean. We can defined covariance between them and thus with about $MxM$ parameters, we can represent our dataset.\n",
    "\n",
    "We will assume the dataset as described in section 3.2.4 above. Where we collect N samples for each of M dimensions.\n",
    "\n",
    "Lets also define $\\mathbf{ss_{k}}$ as the k'th column of matrix $\\mathbf{S}$ i.e $\\mathbf{ss_{k}}$ represents all the samples we collected for the k'th dimensions and is defined as\n",
    "$$ \\mathbf{ss_{k}} = (s_{1k}, s_{2k}, \\cdots ,s_{nk})^{T} $$\n",
    "\n",
    "The [Covariance Matrix](https://en.wikipedia.org/wiki/Covariance_matrix)  $M \\times M$ matrix and is defined as\n",
    "\n",
    "$$\\Sigma = (\\Sigma_{ij}) \\in \\Re^{M \\times M}$$\n",
    "\n",
    "* Each $\\Sigma_{ij}$ is a covariance of ith and jth dimensions and is given by\n",
    "\n",
    "\\begin{align}\n",
    "\\Sigma_{ij} &= cov(\\mathbf{ss_{i}}, \\mathbf{ss_{j}}) \\\\\n",
    " &= \\mathbb{E}(\\mathbf{ss_{i}}, \\mathbf{ss_{j}}) && \\text{from the defn of covariance with zero means}\\\\\n",
    " &= \\frac{1}{N} \\sum_{m=1}^{N}(ss_{mi} \\times {ss_{mj}})\\\\\n",
    "\\end{align}\n",
    "\n",
    "Note that the above expression can be compactly represented in [covariance matrix form ](https://en.wikipedia.org/wiki/Covariance_matrix#Definition)\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\Sigma &= \\mathbb{E}(\\mathbf{s},\\mathbf{s}^{T})\\\\\n",
    "\\Sigma & = \\frac{1}{N}\\sum_{i=1}^{N}(\\mathbf{s_{i}}\\mathbf{s_{i}}^{T})\\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{orange}{\\mathbf{PT.}} \\color{darkblue}{\\mathbf{\\text{ Probability Theory .}}} $<a name=\"prob\"></a>\n",
    "\n",
    "We encourage user to consult this [excellent book](https://www.amazon.com/Probability-Theory-Science-T-Jaynes/dp/0521592712) and [wiki](https://en.wikipedia.org/wiki/Probability_theory) for indepth probability theory.\n",
    "Here we will discuss quick overview for the topic that are relevant to the Kmeans mathemathical formulation.\n",
    "\n",
    "\n",
    "## $\\color{orange}{\\mathbf{PT.1.}} \\color{darkblue}{\\mathbf{\\text{ Random Variables.}}} $<a name=\"prob_rv\"></a>\n",
    "\n",
    "\n",
    "##### $\\color{orange}{\\mathbf{PT.1.1}} \\color{darkblue}{\\mathbf{\\text{ How Random Variable (RV) arises and it's measurement in terms of Probability.}}} $\n",
    "\n",
    "In real life, we can't always pinpoints the output of the events. Event could be any action for example rolling a dice, \n",
    "picking a random person for survey and etc. However in all the cases, the number of possible outcome is fixed and hence instead of talking in concreate terms, we would like to think in terms of possibilities i.e if we roll a dice, what is the possibility that we will get a number $6$ and we know that for unbiased dice it is $\\frac{1}{6}$. Just in this case outcome $X$ is a random variable and it's specific outcome i.e output 6 is one instance of random variable is usually denoted with lower case i.e $x$. It's possibilities i.e probability is measure between $0$ and $1$ and is denoted by $$p(x) = p(X=x) = p(X=6)$$.\n",
    "\n",
    "## $\\color{orange}{\\mathbf{PT.2.}} \\color{darkblue}{\\mathbf{\\text{ Properties of Probability.}}} $<a name=\"prob_prop\"></a>\n",
    "\n",
    "##### $\\color{orange}{\\mathbf{PT.2.1}} \\color{darkblue}{\\mathbf{\\text{ Joint Probability of more than one Events.}}} $\n",
    "\n",
    "Continuing our analogy, if we roll our dice multiple times and get two continous sixes, we can win the game.\n",
    "Just we expect two events to occur one after the another. In terms of notation, if first and second events are represented by random variables $X_1$ and $X_2$ and their outputs are represented by $x_1$ $x_@$ respectively, then this probability is given by \n",
    "\n",
    "$$\n",
    "joint\\_probability\\_of\\_first\\_rv\\_is\\_x_1\\_and\\_second\\_rv\\_is\\_x_2 =  p(x_1, x_2) = p(X_1=x_1, X_2=x_2) = p(X_1=6, X_2=6)\n",
    "$$\n",
    "\n",
    "In general, if we have N events, each represented by random variables $X_i; \\forall i \\in (1,2, \\cdots, N)$ and their correspoding outputs as $x_i; \\forall i \\in (1,2, \\cdots, N)$, then their joint distribution is given by \n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "p(x_1, x_2, \\cdots, x_N) = p(X_1=x_1, X_2==x_2, \\cdots, X_N)\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "##### $\\color{orange}{\\mathbf{PT.2.2}} \\color{darkblue}{\\mathbf{\\text{ Probability of Conditional Event.}}} $\n",
    "\n",
    "In previous section, we saw that we can represent joint probability distribution of more than one random variable. Now, lets consider another case, where we have been playing game of dice and on first throw, we got number six. Since we only win the game, if we get two consequitive six. We ask ourself, what is the probability that we will get another six in second throw, given we got a six in first throw? This is what the conditional probability is used for and is extremely useful in machine learning, since we are always interested in finding the probability of an event given that some other events has occured.\n",
    "\n",
    "\n",
    "\n",
    "The above is represented notationaly as follows:\n",
    "\n",
    "\\begin{align}\n",
    "probability\\_that\\_second\\_rv\\_is\\_x_2\\_given\\_that\\_first\\_rv\\_is\\_x_1 = \\\\\n",
    " &= p(x_2|x_1) && \\ \\ \\text{;notation of conditional probability}\\\\\n",
    " &= \\frac{p(x_1, x_2)}{p(x_1)} && \\ \\ \\text{;see previous section for joint probability} \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "In general, if we have N random outputs corresponding to N different random variables, and if we are interested in knowing the probability of Nth event, given that previous $N-1$ events has occured, it can be repesented as\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    " p(x_N|x_1, x_2, \\cdots, x_{N-1}) = \\frac{p(x_1, x_2, \\cdots, x_{N-1}, x_N)}{p(x_1, x_2, \\cdots, x_{N-1})} \n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "\n",
    "##### $\\color{orange}{\\mathbf{PT.2.3}} \\color{darkblue}{\\mathbf{\\text{ Representing Joint Probability in terms of Conditional Probability.}}} $\n",
    "\n",
    "It is often mathemathically convenient to represent joint probability in terms of conditional probability. We can rearrange the previous equation to represent joint probability in terms of conditional probabilityas:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    " joint\\_probability\\_distribution &= p(x_1, x_2, \\cdots, x_{N-1}) \\\\\n",
    " &= p(x_N|x_1, x_2, \\cdots, x_{N-1})\\times \\mathbf{\\{}p(x_1, x_2, \\cdots, x_{N-1})\\mathbf{\\}}  && \\text{; representing joint probability of N variables in terms of conditional proability} \\\\\n",
    " &= p(x_N|x_1, x_2, \\cdots, x_{N-1}) \\times \\mathbf{\\{} p(x_{N-1}|x_1, x_2, \\cdots, x_{N-2})\\times \\mathbf{\\{}p(x_1, x_2, \\cdots, x_{N-2})\\mathbf{\\}} \\mathbf{\\}}  && \\text{; expanding the term in bracket i.e the joint probability of N-1 variables in terms of conditional probability} \\\\\n",
    "  &= p(x_N|x_1, x_2, \\cdots, x_{N-1}) p(x_{N-1}|x_1, x_2, \\cdots, x_{N-2}) p(x_1, x_2, \\cdots, x_{N-2}) && \\text{; removing unnecessary syntax} \\\\\n",
    "  &= p(x_N|x_1, x_2, \\cdots, x_{N-1}) p(x_{N-1}|x_1, x_2, \\cdots, x_{N-2}) \\cdots p(x_{N-i}|x_1, x_2, \\cdots, x_{N-i}) \\cdots p(x_1) && \\text{; recursively expanding joint probability} \\\\\n",
    "\\end{align}\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\implies p(x_1, x_2, \\cdots, x_{N-1})=p(x_N|x_1, x_2, \\cdots, x_{N-1}) p(x_{N-1}|x_1, x_2, \\cdots, x_{N-2}) \\cdots p(x_{N-i}|x_1, x_2, \\cdots, x_{N-i}) \\cdots p(x_1)\n",
    "}\n",
    "$$\n",
    "\n",
    "##### $\\color{orange}{\\mathbf{PT.2.4}} \\color{darkblue}{\\mathbf{\\text{  ProbabiIity of Independent  Events.}}} $\n",
    "\n",
    "###### Intuition and case for two random variables.\n",
    "In many applicaions including machine learning, samples collected are independent, i.e outcome of random variable $X_i$ doesn't depend on $X_j$. We can intuitively justify it by considering rolling of unbiased dice multiple times.\n",
    "If we have a probability of getting six to be $\\frac{1}{6}$ in i'th throw, the probability of getting six will remains the same in any other throw too. In terms of notation for two throw of dice, we can represent them as:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "p(x_1, x_2) &= p(x_1|x_2)p(x_2) \\\\\n",
    "&= p(x_1)p(x_2) && \\text{;Since both outcomes are independent of each other, there is no need for dependency term}\\\\\n",
    "\\end{align}\n",
    "\n",
    "###### For N random variables.\n",
    "\n",
    "For those cases, where all the random variables are independent of each other, we can represent joint probability of N random variables as follows:\n",
    "\n",
    "\\begin{align}\n",
    "p(x_1, x_2, \\cdots, x_N) &= p(x_N|x_1, x_2, \\cdots, x_{N-1}) p(x_{N-1}|x_1, x_2, \\cdots, x_{N-2}) \\cdots p(x_{N-i}|x_1, x_2, \\cdots, x_{N-i}) \\cdots p(x_1) && \\text{; from previous section 3.4.4} \\\\\n",
    "&= p(x_N)p(x_{N-1})\\cdots p(x_{N-i})\\cdots p(x_1) && \\text{;Since all outcomes are independent of each other, there is no need for dependency term}\\\\\n",
    "&= \\prod_{i=1}^{N} p(x_i) && \\text{;represent in compact notation}\n",
    "\\end{align}\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\implies p(x_1, x_2, \\cdots, x_N) = \\prod_{i=1}^{N} p(x_i)\n",
    "}\n",
    "$$\n",
    "\n",
    "##### $\\color{orange}{\\mathbf{PT.2.5}} \\color{darkblue}{\\mathbf{\\text{  Expectation: Generalized Mean.}}} $\n",
    "\n",
    "We saw in ST.0 that we can approximate $N$ samples of scalar variable with it's mean. Mean gives equal weightage to each of $N$ samples and that is the best one can do if we don't know anything about the distribution of the scalar variables. But in the case of random varaible $x$, we know it's probability and we can define the generalized mean as expectation wrt to probability of random variable as the weighted mean as follows:\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "\\text{Expectation of random variable $x$} &= \\text{Weighted mean of $x$ wrt $p(x)$}\\\\\n",
    "&= \\mathbb{E}_{p(x)}(x) = \\mathbb{E}(x) = \\sum_{i=1}^{N}x_ip(x_i)\\\\\n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "##### $\\color{orange}{\\mathbf{PT.2.6}} \\color{darkblue}{\\mathbf{\\text{  Probability as Expectation of Indicator function}}} $\n",
    "\n",
    "###### Indicator Function:\n",
    "\n",
    " Intuitively, it says whether I am interated in some part of the whole. If the whole universe is represented by a set $U$ and If we are interested in a subset $S$ of $U$  (i.e $ S \\subset U $), our interest can be represented by indicator function $\\mathbb{I}$ defined on set $U$ indicating our interest in the subset $S$. Obviously, if an element $u$ of $U$ is in our interest i.e $u$ belongs to $S$ also it maps it to $1$ otherwise $0$.\n",
    " \n",
    "Formally we can write above as:\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "&\\mathbf{\\text{Assumption:}}\\\\\n",
    "&\\hspace{20pt} U = \\{u_1, u_2, \\cdots u_n\\}\\\\\n",
    "&\\hspace{20pt} S \\subset U \\\\\n",
    "&\\mathbf{\\text{Indicator Function:}}\\\\\n",
    "&\\hspace{20pt} \\mathbb{I}(u) = \n",
    "\\begin{cases}\n",
    "1 \\text{ if } u \\in S \\\\\n",
    "0 \\text{ if } u \\notin S \\\\\n",
    "\\end{cases} \n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "\n",
    "###### Relationship between probability and expectation of indicator function.\n",
    "\n",
    "In many analysis, we collect samples i.e observe a part of the whole dataset and we would like to consider the best estimate of our samples. Since certain attribute of samples we collected are of our interest and we represent it using indicator function. Now all the samples though similar will be somewhat different from each other and in such scenerio, we usually use expectation to represent whole samples by one single sample. It turns out that expectation of the indicator function of a set $S$ is just the probability of observing that set $S$ and it can be formalize as:\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "&\\mathbf{\\text{Assumption:}}\\\\\n",
    "&\\hspace{20pt} U = \\{u_1, u_2, \\cdots u_n\\}\\\\\n",
    "&\\hspace{20pt} S \\subset U \\\\\n",
    "&\\mathbf{\\text{Expectation of Indicator Function:}}\\\\\n",
    "&\\hspace{20pt} \\mathbb{E}_{p(u)}\\{\\mathbb{I}(u)\\} = \\sum_{i=0}^{N}\\mathbb{I}(u_i)p(u_i)   && \\text{;From PT.2.5}\\\\\n",
    "&\\hspace{20pt} \\mathbb{E}_{p(u)}\\{\\mathbb{I}(u)\\} =  \\mathbb{I}(u \\in S)p(u \\in S)+  \\mathbb{I}(u \\notin S)p(u \\notin S)  && \\text{;Split u into $S$ and $\\overline{S}$ }\\\\\n",
    "&\\hspace{20pt} \\mathbb{E}_{p(u)}\\{\\mathbb{I}(u)\\} =  1.p(u \\in S)+  0.p(u \\notin S)  && \\text{;Definition of Indicator function}\\\\\n",
    "&\\hspace{20pt} \\mathbb{E}_{p(u)}\\{\\mathbb{I}(u)\\} =  p(u \\in S)  && \\text{;QED}\\\\\n",
    "\\end{align}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{orange}{\\mathbf{PT.3}} \\color{darkblue}{\\mathbf{\\text{ Parametric Distributions.}}} $<a name=\"prob_dist\"></a>\n",
    "\n",
    "It is mathemathically convenient to use probability distributions characterized by parameters. \n",
    "There are some common probability distributions, that we will use often and we will review it here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### $\\color{orange}{\\mathbf{PT.3.1}} \\color{darkblue}{\\mathbf{\\text{  Distributions: Multinomial Distribution.}}} $<a name=\"prob_dist_multi\"></a>\n",
    "\n",
    "[Multinomial distribution](https://en.wikipedia.org/wiki/Multinomial_distribution) arises in various practical scenerio.\n",
    "\n",
    "For example, lets assume we have a biased dice where the expected value of getting 1 is $\\theta_{1}$ and getting 2 is $theta_{2}$ and so on. Note that since when we roll a dice, we may or maynot get out number of interests i.e say number 2 and hence we present each of the events occuring with random variables $Z_{1}, Z_{2}$ and so on. We now roll the dice, N times and, we would like to know what is the probability that we exactly get n1 ones and n2 twos and so on.  The above is given by multinomial distribution. \n",
    "\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "&p(Z_{1} = n_{1}, Z_{2} = n_{2}, \\cdots, Z_{K} = n_{K}) = \\frac{(\\sum_{j=1}^{K}{n_{j}})!}{\\prod_{j=1}^{K}n_{j}!} \\prod_{j=1}^{K}\\theta_{j}^{n_{j}} \\\\\n",
    "&\\qquad Where \\sum_{j=1}^{K}{n_{j}} = N \\ \\ \\ && \\text{;Since sum of all the sub-events is N}\\\\\n",
    "&\\qquad Where \\sum_{j=1}^{K}{\\theta_{j}} = 1 \\ \\ \\ && \\text{;Since $\\theta_{j}$ spans the probability space and must sum to 1}\\\\\n",
    "\\end{align}\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### $\\color{orange}{\\mathbf{PT.3.2}} \\color{darkblue}{\\mathbf{\\text{  MultiVariate Guassian Distribution.}}} $\n",
    "<a name=\"prob_dist_mvn\"></a>\n",
    "\n",
    "###### $\\color{orange}{\\mathbf{PT.3.2.1}} \\color{darkblue}{\\mathbf{\\text{  Joint PDF of MultiVariate Guassian Distribution.}}} $\n",
    "\n",
    "As an example, lets assume we have male candidates in America, what is there heights? We know that on average american male height (lets call it $\\mu_1$) is about 5 feet and 9  inches but we will definitely have the standard deviation ($\\sigma_1$) (see section 3.2.1)  from the average and most male candidates's height will fall in the \n",
    "3 standard deviation and if we take enought samples the random variable height (lets call it $X_1$) will be represented by a guassian distribution and we says that random variable $X_1$ is drawn from one dimensional guassian distribution with mean ($\\mu_1$) and standard deviation ($\\sigma_1$) and is represented as follows: \n",
    "\n",
    "\n",
    "$$\n",
    "    X_1 \\sim  \\mathcal{N}(\\mu_1,\\,\\sigma_1^{2}) \n",
    "$$\n",
    "\n",
    "Since a random variable will give different output for each draw of the samples, we can't exactly represent it unless we use [Probability Distribution](https://en.wikipedia.org/wiki/Probability_distribution). If we call a sample drawn as $x_1$, it's one dimensional Guassian Distribution, it is given by:\n",
    "\n",
    "$$\n",
    "p(x_1) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{- ( {x_1 - \\mu_1 })^2 / {2\\sigma_1^2}}\n",
    "$$\n",
    "\n",
    "\n",
    "Continuing in the above line of thinking lets also add, lets assume that we are also asked to collect weight of the the male candidate and our guassian distribution will now have two random variables, one for height and another for weight. \n",
    "Now, since we know that in general we can assume that weight and height are independent random variable. But in reality there will be some co-relation between them also. It means that if we have k attributes or dimensions, we will have to calculate, $k \\times k$ matrix and is explained in section 3.2.5 . So to represent a multidimensional guassian distribution, we use vector as follows\n",
    "\n",
    "\n",
    "\n",
    "$\\mathbf{X} = (X_1, X_2, \\cdots, X_k)^T$ => represents k dimensional random variable.\n",
    "\n",
    "$\\mathbf{x} = (x_1, x_2, \\cdots, x_k)^T$ => represents k attributes or dimensions drawn for each sample.\n",
    "\n",
    "$\\mathbf{\\mu} = (\\mu_1, \\mu_2, \\cdots, \\mu_k)^T$ => represents k atttrbutes mean.\n",
    "\n",
    "\n",
    "$\\mathbf{\\Sigma}$ => repersents co-variance matrix, (see section 3.2.5)\n",
    "\n",
    "$|\\mathbf{\\Sigma}|$ => represents determinant of covariance matrix\n",
    "\n",
    "${\\mathbf{\\Sigma}}^{-1}$ => represents inverse of co-variance matrix\n",
    "\n",
    "and followings holds true for the random vector $\\mathbf{X}$ and it's probability distribution $p(x)$\n",
    "\n",
    "\n",
    "$$\n",
    "\\normalsize\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "&\\mathbf{X} \\sim  \\mathcal{N}(\\mathbf{\\mu},\\, \\mathbf{\\Sigma}) && \\text{ ; a vector of rv X is drawn from Normal distribution with vectors parameters $(\\mathbf{\\mu}, \\mathbf{\\Sigma})$}\\\\\n",
    "&p(\\mathbf{x}) = \\frac{1}{\\sqrt{2\\pi} \\sqrt{|\\mathbf{\\Sigma}|}} e^{- \\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu})^T{\\mathbf{\\Sigma}}^{-1}(\\mathbf{x} - \\mathbf{\\mu})} && \\text{ ; vector $\\mathbf{x}$ is a sample of vector random variable and $p(\\mathbf{x})$ is probability of observing $\\mathbf{x}$} \\\\\n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "\n",
    "[see also](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### $\\color{orange}{\\mathbf{PT.3.2.2}} \\color{darkblue}{\\mathbf{\\text{ Conditional  PDF of MultiVariate Guassian Distribution.}}} $\n",
    "\n",
    "\n",
    "In many application, we model dataset using Multivariate Gaussian Distribution. i.e. we assume that a vector of random variable $\\normalsize  \\mathbf{x} = (x_1, x_2, \\cdots, x_k)^T$ is drawn from  $\\normalsize  \\mathcal{N}(\\mathbf{\\mu},\\, \\mathbf{\\Sigma})$.\n",
    "\n",
    "Typically, we first train multivariate Gaussian by estimating it's parameters mean $\\normalsize  \\mathbf{\\mu} = (\\mu_1, \\mu_2, \\cdots, \\mu_k)^T$ and covariance $\\normalsize  \\mathbf{\\Sigma} = \\begin{pmatrix}\\sigma_{11}  &\\sigma_{12} &\\cdots &\\sigma_{1k} \\\\ \\sigma_{21}  &\\sigma_{22} &\\cdots &\\sigma_{2k} \\\\ \\vdots &\\vdots &\\ddots &\\vdots \\\\ \\sigma_{k1}  &\\sigma_{k2} &\\cdots &\\sigma_{kk}\\end{pmatrix}$\n",
    "\n",
    "Then, we predict the output given a part of the sample vector. For example, we might be given only a subset of $\\normalsize  \\mathbf{x} = (x_1, x_2, \\cdots, x_k)^T$ i.e. $\\normalsize  \\mathbf{x}_{g} = (x_1, x_2, \\cdots, x_g)^T$ with $a < k$ as an input to our model $\\normalsize \\mathcal{N}(\\mathbf{\\mu},\\, \\mathbf{\\Sigma})$. And we are asked to predict remaining variables i.e. $\\normalsize \\mathbf{x}_{p} = (x_1, x_2, \\cdots, x_p)^T$ with $p < k$ and $g+p = k$. We can find $\\normalsize  \\mathbf{x}_{p}$ using conditional probability $\\normalsize  p(\\mathbf{x}_{p}|\\mathbf{x}_{g})$.\n",
    "\n",
    "One can [derive](https://stats.stackexchange.com/questions/30588/deriving-the-conditional-distributions-of-a-multivariate-normal-distribution) that the conditional probability $p(\\mathbf{x}_{p}|\\mathbf{x}_{g})$ itself a Multivariate Gaussian $\\normalsize  \\mathcal{N}(\\mathbf{\\mu}_{p|g},\\mathbf{\\Sigma}_{p|g})$ with mean $\\normalsize  \\mathbf{\\mu}_{p|g}$ and covariance matrix $\\normalsize \\mathbf{\\Sigma}_{p|g}$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "&\\mathbf{Given:}\\\\\n",
    "&\\hspace{15pt}\\text{Trained Model:} \\mathcal{N}(\\mathbf{\\mu}_{k\\times 1},\\, \\mathbf{\\Sigma}_{k\\times k})\\\\\n",
    "&\\hspace{15pt}\\text{Prediction Input:}  \\mathbf{x}_{g} = (x_1, x_2, \\cdots, x_g)^T  \\text{; $g < k$}\\\\\n",
    "&\\hspace{15pt}\\text{Prediction Output:}   \\mathbf{x}_{p} = (x_1, x_2, \\cdots, x_p)^T \\text{; $p < k$ and $g+p=k$}\\\\\n",
    "&\\mathbf{Pre-process:}\\\\\n",
    "&\\hspace{15pt}\\because \\text{  } \\mathbf{x} = \\begin{pmatrix}\\mathbf{x}_{g} \\\\ \\mathbf{x}_{p}\\end{pmatrix} \\sim \\mathcal{N}(\\mathbf{\\mu}_{k\\times 1},\\, \\mathbf{\\Sigma}_{k\\times k})\\\\ \n",
    "&\\hspace{15pt}\\therefore \\text{Create Blocks of $\\mu$ and $\\Sigma$ as:}\\\\\n",
    "&\\hspace{15pt}\\hspace{30pt} \\mathbf{\\mu} = \\begin{pmatrix}\\mathbf{\\mu}_{g} \\\\ \\mathbf{\\mu}_{p}\\end{pmatrix} \\\\\n",
    "&\\hspace{15pt}\\hspace{30pt} \\mathbf{\\Sigma} = \\begin{pmatrix}\\mathbf{\\Sigma}_{gg} &\\mathbf{\\Sigma}_{gp}\\\\ \\mathbf{\\Sigma}_{pg} &\\mathbf{\\Sigma}_{pp}\\end{pmatrix} \\\\\n",
    "&\\mathbf{Prediction:} \\mathbf{x}_{p} \\sim \\mathcal{N}(\\mathbf{\\mu}_{p|g},\\, \\mathbf{\\Sigma}_{p|g})\\\\\n",
    "&\\hspace{15pt} p(\\mathbf{x}_{p}|\\mathbf{x}_{g}) = \\frac{p(\\mathbf{x}_{p},\\mathbf{x}_{g})}{p(\\mathbf{x}_{g})} = \\mathcal{N}(\\mathbf{\\mu}_{p|g},\\, \\mathbf{\\Sigma}_{p|g})\\\\\n",
    "&\\hspace{15pt} \\text{where:}\\\\\n",
    "&\\hspace{15pt} \\hspace{15pt} \\mathbf{\\mu}_{p|g} = \\mathbf{\\mu}_{p} + \\Sigma_{pg}\\Sigma^{-1}_{gg}(\\mathbf{x}_{g} - \\mathbf{\\mu}_{g}) \\\\\n",
    "&\\hspace{15pt} \\hspace{15pt}  \\mathbf{\\Sigma}_{p|g} = \\mathbf{\\Sigma}_{pp} - \\Sigma_{pg}\\Sigma^{-1}_{pp}\\Sigma_{gp}\n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## $\\color{orange}{\\mathbf{PT.4}} \\color{darkblue}{\\mathbf{\\text{ Bayes Theorem.}}} $<a name=\"prob_bayes\"></a>\n",
    "\n",
    "Bayes Theorem is remarkably simple concept, which allows one to iteratively, refined the belief in light of new evidences. It is given by \n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "p(\\color{green}{\\mathbf{posterier}}) \\propto p(\\color{blue}{\\mathbf{likelihood}}) \\times p(\\color{purple}{\\mathbf{prior}})\n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "And more details is at [Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# $\\color{orange}{\\mathbf{NT.}} \\color{darkblue}{\\mathbf{\\text{  Numerical Techniques.}}} $<a name=\"num_tech\"></a>\n",
    "\n",
    "\n",
    "We will review, commonly used numerical tecnhiques in Machine Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{orange}{\\mathbf{NT.1}} \\color{darkblue}{\\mathbf{\\text{  Maximizing Vector Values Functions.}}} $\n",
    "\n",
    "### $\\color{orange}{\\mathbf{NT.1.1}} \\color{darkblue}{\\mathbf{\\text{  Maximizing a Function via Matrix Calculus.}}} $<a name=\"num_max_cal\"></a>\n",
    "\n",
    "There are many numerical algorithm for maximizing and many good book on numerical optimization talks about it.\n",
    "\n",
    "We will explain the concept on simple using [Matrix Calculus](https://en.wikipedia.org/wiki/Matrix_calculus)\n",
    "\n",
    "Condition for maximizing\n",
    "* The condition for critical points (i.e maximum or minimum) is that each component of first vector derivative should be zero i.e tangent (interpretation of first derivative) is parallel to x axis at the point of maximum or minimum\n",
    "\n",
    "* The condition on a critical point (found by first derivative) to be maximum is that second vector derivative must be positive for each component. i.e rate of change of tangent is increasing at maximum point.\n",
    "\n",
    "\n",
    "If the vector variables is represented by $ \\normalsize \\Theta = (\\theta_1, \\theta_2, \\cdots, \\theta_m)$, then functional on \\Theta will be represented by $\\normalsize \\mathcal{F}(\\Theta)$\n",
    "\n",
    "What is our variables here? Since we want to find the maximum wrt to parameter vector $\\Theta$. We can differentiate wrt each of the components i.e $(\\theta_1, \\theta_2, \\cdots, \\theta_m)$ and equate each of the equations to zero. We can also verify that it is in fact maximum by finding the second derivative and making sure that it is always positive.\n",
    "\n",
    "\n",
    "The above can be summarized as:\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "&\\frac{\\partial^1\\big[\\mathbf{\\mathcal{F}}(\\Theta)\\big]}{\\partial^1 \\Theta} \\mathbf{=} \\mathbf{0} && \\text{ ; vector $\\mathbf{0}$ means all the m components are component wise zero} \\\\\n",
    "&\\frac{\\partial^2\\big[\\mathbf{\\mathcal{F}}(\\Theta)\\big]}{\\partial^2 \\Theta} \\mathbf{\\succ} \\mathbf{0} && \\text{ ; greater than vector $\\mathbf{0}$ means all the m components are component wise greater than zero} \\\\\n",
    "\\end{align}\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{orange}{\\mathbf{NT.2}} \\color{darkblue}{\\mathbf{\\text{  MLE Techniques.}}} $<a name=\"num_mle\"></a>\n",
    "\n",
    "### $\\color{orange}{\\mathbf{NT.2.1}} \\color{darkblue}{\\mathbf{\\text{  Likelihood Function.}}} $\n",
    "\n",
    "\n",
    "\n",
    "Machine learning is about modeling i.e you have seen something and you wonder can I predict those dataset in future?\n",
    "Model can be described by a set of parameters. Those parameters could be co-efficient in linear model or it could be the parameters of the probability distribution that our data sets are generated from? So in this line of thinking, we can see that if we are interested in finding best parameters. That is by definition is called likelyhood of data.\n",
    "\n",
    "Likelihood is refering to the events that has occured in the past i.e (our observation or our datasets) and we are trying to model it using parameters. That is same as saying what if my parameters are correct, what is the probability of observing my future events i.e (our future observation or our future datasets). Thus, we have established a relationship between likelihood of the past data to the probability of future data linked by parameters.\n",
    "\n",
    "In notations, the above discussion can be summarised as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\mathcal{L}}(parameters, model\\mathbf{|}Dataset) = p(Dataset\\mathbf{|}parameters,model)\n",
    "$$\n",
    "\n",
    "Since, we represent our dataset as a matrix $\\mathbf{X}$ where each row corresponds to one data point or data vector.\n",
    "and our model are represented as parametric probability distribution may contains many parameters i.e $(\\theta_1, \\theta_2, \\cdots, \\theta_m)$ and we can compactly represent them by vector $\\Theta$ and likelihood as:\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "&\\mathbf{\\mathcal{L}}(\\Theta\\mathbf{|}\\mathbf{X}) = p(\\mathbf{X}\\mathbf{|}\\Theta) && \\text{ ; we will use definition later} \\\\\n",
    "& Where\\ \\ \\Theta = (\\theta_1, \\theta_2, \\cdots, \\theta_m) \n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "\n",
    "**NOTE**:\n",
    "* In practice, we use log likelyhood instead of likehood.\n",
    "* Since likelihood of past data is same as probability of future data for a set of parameters, it ranges from 0 to 1 inclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{orange}{\\mathbf{NT.2.2}} \\color{darkblue}{\\mathbf{\\text{  Likelihood to Log Likelyhood.}}} $\n",
    "\n",
    "In Machine learning, we are trying to learn model or it's parameters and to we have to choose parameters which maximizes the probability of occurence of data. Maximization involves taking first and second vector derivative of the joint probability. The above operation can \n",
    "\n",
    "Logarithm is mathemathically convenient function because of :\n",
    "\n",
    "* It is the monotonic increasing function, taking logarithm of both sides, won't change the  coordinate of it's maximum point or vector. \n",
    "\n",
    "* Logarithm converts multiplication into summation and maximizing (i.e takings it's derivatives) is much simpler.\n",
    "\n",
    "Notationally, log likelyhood is expressed as \n",
    "$$\n",
    "\\color{brown}{\n",
    "\\begin{align}\n",
    "\\mathbf{\\mathcal{LL}}(\\Theta\\mathbf{|}\\mathbf{X}) = log(\\mathbf{\\mathcal{L}}(\\Theta\\mathbf{|}\\mathbf{X})) = log(p(\\mathbf{X}\\mathbf{|}\\Theta)) && \\text{ ; we will use definition later}\n",
    "\\end{align}\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{orange}{\\mathbf{NT.2.3}} \\color{darkblue}{\\mathbf{\\text{  Maximum Likelihood Estimation (MLE).}}} $\n",
    "\n",
    "Since likelihood is function $\\Theta$, for every choice of $\\hat{\\Theta} \\in \\Theta$, we will get different likelihood. Which $\\hat{\\Theta}$ should we choose? Intuively, we would like to have $\\hat{\\Theta}$ which maximizes our likelihood function. This is another way of saying that we want to choose $\\hat{\\Theta}$ that maximizes our confidence in the likelihood function.\n",
    "\n",
    "The above discussion is summaraized as:\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "\\hat{\\Theta} &= arg\\ max\\ \\mathbf{\\mathcal{L}}(\\Theta\\mathbf{|}\\mathbf{X}) && \\text{ ; $\\hat{\\Theta}$ represents best estimation of parameters vector} \\\\\n",
    "\\hat{\\Theta} &= arg\\ max\\ \\mathbf{\\mathcal{LL}}(\\Theta\\mathbf{|}\\mathbf{X}) && \\text{ ; As discussed in previous section we will get same answer for normal and log function }\n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "In practice, we often use empirical frequency counting to estimate probability and it can be proven that estimating probability using frequency is also MLE estimate.\n",
    "\n",
    "For example if we would like to find probability of observing various numbers for a biased.\n",
    "We just roll many times (for example 10000 and we will call it $freq_{all}$) and count the number of times 1 occurs (i.e $freq_1$), 2 occurs (i.e $freq_2$) and so on.\n",
    "\n",
    "Then the probability is given by:\n",
    "\n",
    "\\begin{equation}\n",
    "p(event = i) = \\frac{freq_i}{freq_{all}} ; \\forall\\ i\\ \\in (1,2,\\cdots,6) \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## $\\color{orange}{\\mathbf{NT.3}} \\color{darkblue}{\\mathbf{\\text{ EM Techniques.}}} $<a name=\"num_em\"></a>\n",
    "\n",
    "\n",
    "\n",
    "##### $\\color{orange}{\\mathbf{NT.3.1}} \\color{darkblue}{\\mathbf{\\text{  Maximizing a Function via Expectation Maximization (EM).}}} $\n",
    "\n",
    "###### Background and Intuition.\n",
    "\n",
    "Here is an excellent [short tutorial on Expectation Maximization](http://ai.stanford.edu/~chuongdo/papers/em_tutorial.pdf). Also we recommend this excellent [book by Maya R Gupta](https://www.amazon.com/Theory-Algorithm-Foundations-Trends-Processing/dp/1601984308) for interested user.\n",
    "\n",
    "In many MLE problem, we can't exactly find the closed form solution and we have to perform iterative methods.\n",
    "EM is one of those iterative methods.\n",
    "\n",
    "We will cover a short detail of this algorithm here. EM algorithm is useful for the case of missing or hidden variable.  \n",
    "\n",
    "Lets go back to our favorite dice examples. Lets assume two biased dices with random variable $D_A$ and $D_B$ and we would like to find probability mass function (i.e probability for each of the outcomes).\n",
    "Notationally speaking, we would like to find\n",
    "\n",
    "\\begin{align}\n",
    "& p(D_A = 1) = \\theta_{A1};  p(D_A = 2) = \\theta_{A2}; \\cdots  p(D_A = 6) = \\theta_{A6}; \\\\\n",
    "& p(D_B = 1) = \\theta_{B1};  p(D_B = 2) = \\theta_{B2}; \\cdots  p(D_B = 6) = \\theta_{B6}; \\\\\n",
    "\\end{align}\n",
    "\n",
    "compactly, we can represent using parameter vectors as \n",
    "\\begin{align}\n",
    "& pmf(D_A) = \\Theta_{A} = (\\theta_{A1}, \\theta_{A2}, \\cdots,\\theta_{A6}) ; \\\\\n",
    "& pmf(D_B) = \\Theta_{B} = (\\theta_{B1}, \\theta_{B2}, \\cdots,\\theta_{B6}) ; \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "As we explained in section 3.3.3, we can just use the frequency counting to have the MLE of probability mass function. In words, we can roll each dice many times and \n",
    "\n",
    "Lets add a twist i.e we are given the outcome and we don't know whether it was generated from dice $D_A$ or $D_B$. How can we find the MLE probability mass function? Well since we don't know which dice generated our outcome, the best we can assume that a outcome can be generated from either of dices. \n",
    "\n",
    "In shorts, given a unknown dice, we just roll it many times and estimate or the posterior probability of each of the dice, using Bayes Theorem (see section ). This will act as the weights of the original samples. This steps is called **Expectation Step (E-Step)**.\n",
    "\n",
    "Then, given our weights on data, we again compute the MLE estimate of the data using frequency count. But this time, instead of using the original frequency, we use the weighted frequency . The weights being the posterior computed from  (E-step). This is called **Maximization Step(M-Step)**. Since in the maximization step, we used our better guess, it is more closer to the actual probability. \n",
    "\n",
    "We can iterate over E-Step and M-Step until convergence.\n",
    "\n",
    "###### Developing the pseudocode.\n",
    "\n",
    "Above ** Expectation Maximization Algorithm** can be summarized as follows\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "&\\hspace{1pt} \\hat{\\Theta}^{(t)} \\text{ : be estimated parameter vectors for current iteration;}\\\\\n",
    "&\\hspace{1pt} \\hat{\\Theta}^{(t+1)} \\text{ : be estimated parameter vectors for next iteration;}\\\\\n",
    "&\\hspace{1pt} \\text{ Set initial current_parameters to some random values ;}\\\\\n",
    "&\\hspace{1pt} \\text{ Repeat Until Convergence:}\\\\\n",
    "&\\hspace{10pt} \\text{ Begin:}\\\\\n",
    "&\\hspace{25pt} \\text{ set current_parameters values to next_parameters;}\\\\\n",
    "&\\hspace{25pt} \\text{ 1. Perform E-Step using current_parameters and get the new set of weighted data;}\\\\\n",
    "&\\hspace{25pt} \\text{ 2. using MLE compute the best parameters and call it next_parameters;}\\\\\n",
    "&\\hspace{10pt} \\text{ End:}\\\\\n",
    "\\end{align}\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "###### EM Algorithm.\n",
    "\n",
    "Lets put the above algorithm in the more convenient form.\n",
    "\n",
    "Since, we have already established the relationship between likelihood and probability. Here our dataset consists of $K$ hidden variable also, lets call it $\\mathbf{Z} = (\\mathbf{z_1}, \\mathbf{z_1}, \\cdots, \\mathbf{z_K})$ and dataset as $\\mathbf{X}$ (see section 3.2.3 ).\n",
    "\n",
    "$$\n",
    "\\color{darkred}{\n",
    "\\begin{align}\n",
    "&\\mathbf{E-Step:}\\\\\n",
    "&\\hspace{15pt} Q(\\Theta|\\hat{\\Theta}^{(t)}) = \\mathcal{E}_{\\mathbf{Z|X,\\hat{\\Theta}^{(t)}}}[\\mathcal{LL}(\\Theta\\mathbf{|}\\mathbf{X,Z})] && \\text{ ; Expected value of log likelihood wrt $\\mathbf{Z}$ given dataset &$\\mathbf{X}$ and last iteration's estimated parameters $\\hat{\\Theta}^{(t)}$. }\\\\\n",
    "&\\mathbf{M-Step:}\\\\\n",
    "&\\hspace{15pt} \\hat{\\Theta}^{(t+1)} = argmax_{\\Theta} \\mathbf{\\mathcal{LL}}(\\mathcal{Q}(\\Theta\\mathbf{|}\\hat{\\Theta}^{(t)}) && \\text{ ; find the next iteration parameter $\\hat{\\Theta}^{(t+1)}$ by maximizing the expected log likelihood defined in E-step wrt $\\Theta$.}\\\\\n",
    "\\end{align}\n",
    "}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
